{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ai_trade_model.py â€” AI-Trade Model (14-Feature Aligned, Colab-Ready)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import joblib, zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "zSjlht7cqvXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Config â”€â”€â”€\n",
        "SEQLEN = 20\n",
        "zones_file = \"ai_training_data.parquet\"\n",
        "ohlcv_file = \"1m_ohlcv.csv\"\n",
        "\n",
        "# â”€â”€â”€ Load Zone Dataset â”€â”€â”€\n",
        "print(\"ğŸ“¥ Loading dataset ...\")\n",
        "zones = pd.read_parquet(zones_file)\n",
        "if \"timestamp\" not in zones.columns:\n",
        "    zones.rename(columns={\"time\": \"timestamp\"}, inplace=True)\n",
        "zones[\"timestamp\"] = pd.to_datetime(zones[\"timestamp\"])\n",
        "zones = zones.dropna(subset=[\"result\"])\n",
        "zones[\"result\"] = zones[\"result\"].astype(str)\n",
        "\n",
        "# Encode target\n",
        "label_encoder = LabelEncoder()\n",
        "zones[\"result_encoded\"] = label_encoder.fit_transform(zones[\"result\"])\n",
        "joblib.dump(label_encoder, \"Label_Encoder.pkl\")\n",
        "\n",
        "zones[\"is_tp2\"] = (zones[\"result\"] == \"tp2\").astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7xMGGCgqvEz",
        "outputId": "e8d38be8-1d94-4c23-db77-13bca75fb5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Loading dataset ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Load OHLCV Dataset â”€â”€â”€\n",
        "print(\"ğŸ“¥ Loading OHLCV data ...\")\n",
        "ohlcv = pd.read_csv(ohlcv_file)\n",
        "if \"timestamp\" not in ohlcv.columns:\n",
        "    ohlcv.rename(columns={\"time\": \"timestamp\"}, inplace=True)\n",
        "ohlcv[\"timestamp\"] = pd.to_datetime(ohlcv[\"timestamp\"])\n",
        "ohlcv = ohlcv.set_index(\"timestamp\").sort_index()\n",
        "ohlcv = ohlcv[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS0KrxfdqvBn",
        "outputId": "9968c088-b40d-4539-86d9-ca948cc43af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Loading OHLCV data ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Feature Engineering â”€â”€â”€\n",
        "extra_cols = [\n",
        "    \"rsi\", \"atr\", \"rr\", \"zone_distance\", \"momentum_strength\", \"adx\",\n",
        "    \"pinbar\", \"engulfing\", \"choch_angle\", \"volume_slope\"\n",
        "]\n",
        "for col in extra_cols:\n",
        "    if col not in zones.columns:\n",
        "        zones[col] = 0.0\n",
        "\n",
        "# Dummy encode zone_type with both demand and supply columns\n",
        "zones = pd.get_dummies(zones, columns=[\"zone_type\"])\n",
        "if \"zone_type_demand\" not in zones.columns:\n",
        "    zones[\"zone_type_demand\"] = 0\n",
        "if \"zone_type_supply\" not in zones.columns:\n",
        "    zones[\"zone_type_supply\"] = 0\n",
        "\n",
        "# Trend encoding\n",
        "zones[\"trend_encoded\"] = zones[\"trend\"].map({\"bullish\": 1, \"bearish\": -1, \"sideways\": 0}).fillna(0)\n",
        "\n",
        "# Ensure in_zone exists\n",
        "if \"in_zone\" not in zones.columns:\n",
        "    zones[\"in_zone\"] = 0\n",
        "\n",
        "# Meta feature order â€” exactly 14 features\n",
        "meta_features = [\n",
        "    \"rsi\", \"atr\", \"rr\", \"zone_distance\", \"momentum_strength\", \"adx\",\n",
        "    \"pinbar\", \"engulfing\", \"choch_angle\", \"volume_slope\",\n",
        "    \"in_zone\", \"zone_type_demand\", \"zone_type_supply\", \"trend_encoded\"\n",
        "]\n",
        "\n",
        "# Scale meta features\n",
        "scaler = StandardScaler()\n",
        "zones[meta_features] = scaler.fit_transform(zones[meta_features].fillna(0))\n",
        "joblib.dump(scaler, \"Scaler.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNpCJeFmqu_D",
        "outputId": "48855ad5-002a-4aff-bbbc-b704adc8c049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Build sequences â”€â”€â”€\n",
        "features, targets, extras = [], [], []\n",
        "for _, row in zones.iterrows():\n",
        "    ts = row[\"timestamp\"]\n",
        "    window = ohlcv.loc[:ts].tail(SEQLEN)\n",
        "    if len(window) == SEQLEN:\n",
        "        features.append(window.values)\n",
        "        targets.append(row[\"result_encoded\"])\n",
        "        extras.append([row[feat] for feat in meta_features])\n",
        "\n",
        "X_seq = np.array(features, dtype=np.float32)\n",
        "X_meta = np.array(extras, dtype=np.float32)\n",
        "y_multi = np.array(targets)\n",
        "y_binary = (y_multi == label_encoder.transform([\"tp2\"])[0]).astype(int)"
      ],
      "metadata": {
        "id": "-Vwev8vIqu8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ SMOTE Oversampling for Multi-class â”€â”€â”€\n",
        "print(\"ğŸ“ˆ Applying SMOTE for multi-class oversampling...\")\n",
        "\n",
        "# --- NEW: Remove any rare classes (< 2 samples) before SMOTE ---\n",
        "class_counts = pd.Series(y_multi).value_counts()\n",
        "rare_classes = class_counts[class_counts < 2].index.tolist()\n",
        "if rare_classes:\n",
        "    print(f\"âš  Removing rare classes with < 2 samples: {rare_classes}\")\n",
        "    mask = ~np.isin(y_multi, rare_classes)\n",
        "    X_seq, X_meta, y_multi = X_seq[mask], X_meta[mask], y_multi[mask]\n",
        "\n",
        "# Re-encode target labels after removing rare classes\n",
        "unique_labels = np.unique(y_multi)\n",
        "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "y_multi = np.array([label_mapping[label] for label in y_multi])\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "X_seq_flat = X_seq.reshape(X_seq.shape[0], -1)\n",
        "X_all = np.hstack([X_seq_flat, X_meta])\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_all = imputer.fit_transform(X_all)\n",
        "\n",
        "# NEW: Set k_neighbors=1 to ensure SMOTE can run on any class with >= 2 samples\n",
        "sm = SMOTE(k_neighbors=1, random_state=42)\n",
        "X_all_res, y_multi_res = sm.fit_resample(X_all, y_multi)\n",
        "\n",
        "X_seq_res = X_all_res[:, :SEQLEN*5].reshape(-1, SEQLEN, 5)\n",
        "X_meta_res = X_all_res[:, SEQLEN*5:]\n",
        "\n",
        "# â”€â”€â”€ Train/Validation Split â”€â”€â”€\n",
        "X_seq_train, X_seq_val, X_meta_train, X_meta_val, y_train_multi, y_val_multi = train_test_split(\n",
        "    X_seq_res, X_meta_res, y_multi_res, test_size=0.2, stratify=y_multi_res, random_state=42\n",
        ")\n",
        "# Re-split for binary model using the same data, but with binary labels\n",
        "y_binary_res = (y_multi_res == label_encoder.transform([\"tp2\"])[0]).astype(int)\n",
        "_, _, _, _, y_train_bin, y_val_bin = train_test_split(\n",
        "    X_seq_res, X_meta_res, y_binary_res, test_size=0.2, stratify=y_binary_res, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GFMrYSzqu5z",
        "outputId": "6d1d7c8b-34ca-437c-d009-42b1b0ee64bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ˆ Applying SMOTE for multi-class oversampling...\n",
            "âš  Removing rare classes with < 2 samples: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Train/Validation Split â”€â”€â”€\n",
        "X_seq_train, X_seq_val, X_meta_train, X_meta_val, y_train_multi, y_val_multi = train_test_split(\n",
        "    X_seq_res, X_meta_res, y_multi_res, test_size=0.2, stratify=y_multi_res, random_state=42\n",
        ")\n",
        "# Re-split for binary model using the same data, but with binary labels\n",
        "y_binary_res = (y_multi_res == label_encoder.transform([\"tp2\"])[0]).astype(int)\n",
        "_, _, _, _, y_train_bin, y_val_bin = train_test_split(\n",
        "    X_seq_res, X_meta_res, y_binary_res, test_size=0.2, stratify=y_binary_res, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# â”€â”€â”€ Class Weights â”€â”€â”€\n",
        "weights = compute_class_weight('balanced', classes=np.unique(y_train_multi), y=y_train_multi)\n",
        "class_weights = dict(zip(np.unique(y_train_multi), weights))\n",
        "print(f\"â„¹ï¸ Class weights: {class_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Am_L2aqu3Q",
        "outputId": "cc945ff8-2bae-4151-cfae-43b682dcf80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â„¹ï¸ Class weights: {np.int64(0): np.float64(0.9999446014071243), np.int64(1): np.float64(0.9999446014071243), np.int64(2): np.float64(1.0001108156028369)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Multi-class Model (Updated) â”€â”€â”€\n",
        "seq_input = layers.Input(shape=(SEQLEN, 5), name=\"sequence_input\")\n",
        "x = layers.Bidirectional(layers.GRU(128, return_sequences=True))(seq_input)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Bidirectional(layers.GRU(64, return_sequences=True))(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "query = layers.Dense(128)(x)\n",
        "attention_layer = layers.Attention()\n",
        "attn_out = attention_layer([query, x])\n",
        "x = layers.GlobalAveragePooling1D()(attn_out)\n",
        "\n",
        "meta_input = layers.Input(shape=(X_meta.shape[1],), name=\"meta_input\")\n",
        "y = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(meta_input)\n",
        "y = layers.BatchNormalization()(y)\n",
        "y = layers.Dropout(0.2)(y)\n",
        "\n",
        "combined = layers.concatenate([x, y])\n",
        "combined = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(combined)\n",
        "combined = layers.BatchNormalization()(combined)\n",
        "combined = layers.Dropout(0.3)(combined)\n",
        "\n",
        "output = layers.Dense(len(np.unique(y_train_multi)), activation=\"softmax\")(combined)\n",
        "\n",
        "model = models.Model([seq_input, meta_input], output, name=\"AI-Trade-GRU-Multi\")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "c9MMqeFRqu07",
        "outputId": "95efa4c8-eec9-4314-a199-d0a6585bfde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"AI-Trade-GRU-Multi\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AI-Trade-GRU-Multi\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sequence_input      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m103,680\u001b[0m â”‚ sequence_input[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ bidirectional[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚    \u001b[38;5;34m123,648\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ bidirectional_1[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ meta_input          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚     \u001b[38;5;34m16,512\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m960\u001b[0m â”‚ meta_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      â”‚\n",
              "â”‚ (\u001b[38;5;33mAttention\u001b[0m)         â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚        \u001b[38;5;34m387\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ sequence_input      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">103,680</span> â”‚ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ meta_input          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> â”‚ meta_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         â”‚                   â”‚            â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,427\u001b[0m (1.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,427</span> (1.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m271,043\u001b[0m (1.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,043</span> (1.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Callbacks â”€â”€â”€\n",
        "es = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=12, min_lr=1e-6)\n",
        "\n",
        "# â”€â”€â”€ Training â”€â”€â”€\n",
        "model.fit([X_seq_train, X_meta_train], y_train_multi,\n",
        "          validation_data=([X_seq_val, X_meta_val], y_val_multi),\n",
        "          epochs=500, batch_size=128, class_weight=class_weights,\n",
        "          callbacks=[es, rlr], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy1K93c3quyS",
        "outputId": "f643bde3-f491-4ad7-df27-b8870edb6c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.3535 - loss: 1.4722 - val_accuracy: 0.3565 - val_loss: 1.3270 - learning_rate: 3.0000e-04\n",
            "Epoch 2/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 275ms/step - accuracy: 0.3739 - loss: 1.3760 - val_accuracy: 0.3887 - val_loss: 1.2490 - learning_rate: 3.0000e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 261ms/step - accuracy: 0.3823 - loss: 1.3403 - val_accuracy: 0.3887 - val_loss: 1.2428 - learning_rate: 3.0000e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 255ms/step - accuracy: 0.3777 - loss: 1.3283 - val_accuracy: 0.3878 - val_loss: 1.2429 - learning_rate: 3.0000e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 276ms/step - accuracy: 0.3868 - loss: 1.2953 - val_accuracy: 0.4152 - val_loss: 1.2178 - learning_rate: 3.0000e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 264ms/step - accuracy: 0.3884 - loss: 1.2783 - val_accuracy: 0.4257 - val_loss: 1.2046 - learning_rate: 3.0000e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.4068 - loss: 1.2563 - val_accuracy: 0.4294 - val_loss: 1.1972 - learning_rate: 3.0000e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.4097 - loss: 1.2394 - val_accuracy: 0.4423 - val_loss: 1.1923 - learning_rate: 3.0000e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 268ms/step - accuracy: 0.4112 - loss: 1.2320 - val_accuracy: 0.4381 - val_loss: 1.1829 - learning_rate: 3.0000e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.4206 - loss: 1.2184 - val_accuracy: 0.4367 - val_loss: 1.1816 - learning_rate: 3.0000e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.4289 - loss: 1.2033 - val_accuracy: 0.4396 - val_loss: 1.1730 - learning_rate: 3.0000e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.4251 - loss: 1.1943 - val_accuracy: 0.4272 - val_loss: 1.1719 - learning_rate: 3.0000e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.4229 - loss: 1.1851 - val_accuracy: 0.4463 - val_loss: 1.1606 - learning_rate: 3.0000e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 266ms/step - accuracy: 0.4336 - loss: 1.1795 - val_accuracy: 0.4434 - val_loss: 1.1588 - learning_rate: 3.0000e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 280ms/step - accuracy: 0.4258 - loss: 1.1779 - val_accuracy: 0.4425 - val_loss: 1.1606 - learning_rate: 3.0000e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.4305 - loss: 1.1710 - val_accuracy: 0.4398 - val_loss: 1.1555 - learning_rate: 3.0000e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.4238 - loss: 1.1718 - val_accuracy: 0.4394 - val_loss: 1.1548 - learning_rate: 3.0000e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.4283 - loss: 1.1634 - val_accuracy: 0.4414 - val_loss: 1.1462 - learning_rate: 3.0000e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.4338 - loss: 1.1504 - val_accuracy: 0.4485 - val_loss: 1.1379 - learning_rate: 3.0000e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.4413 - loss: 1.1440 - val_accuracy: 0.4374 - val_loss: 1.1362 - learning_rate: 3.0000e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 265ms/step - accuracy: 0.4369 - loss: 1.1438 - val_accuracy: 0.4540 - val_loss: 1.1285 - learning_rate: 3.0000e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 262ms/step - accuracy: 0.4447 - loss: 1.1330 - val_accuracy: 0.4234 - val_loss: 1.1445 - learning_rate: 3.0000e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.4416 - loss: 1.1351 - val_accuracy: 0.4622 - val_loss: 1.1186 - learning_rate: 3.0000e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.4450 - loss: 1.1301 - val_accuracy: 0.4565 - val_loss: 1.1152 - learning_rate: 3.0000e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 266ms/step - accuracy: 0.4473 - loss: 1.1234 - val_accuracy: 0.4460 - val_loss: 1.1215 - learning_rate: 3.0000e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.4238 - loss: 1.1339 - val_accuracy: 0.4474 - val_loss: 1.1180 - learning_rate: 3.0000e-04\n",
            "Epoch 27/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 264ms/step - accuracy: 0.4466 - loss: 1.1159 - val_accuracy: 0.4556 - val_loss: 1.1091 - learning_rate: 3.0000e-04\n",
            "Epoch 28/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.4383 - loss: 1.1161 - val_accuracy: 0.4618 - val_loss: 1.1061 - learning_rate: 3.0000e-04\n",
            "Epoch 29/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.4493 - loss: 1.1098 - val_accuracy: 0.4560 - val_loss: 1.1063 - learning_rate: 3.0000e-04\n",
            "Epoch 30/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 275ms/step - accuracy: 0.4398 - loss: 1.1068 - val_accuracy: 0.4567 - val_loss: 1.0964 - learning_rate: 3.0000e-04\n",
            "Epoch 31/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.4480 - loss: 1.1033 - val_accuracy: 0.4478 - val_loss: 1.0992 - learning_rate: 3.0000e-04\n",
            "Epoch 32/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.4548 - loss: 1.0966 - val_accuracy: 0.4686 - val_loss: 1.0929 - learning_rate: 3.0000e-04\n",
            "Epoch 33/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 266ms/step - accuracy: 0.4549 - loss: 1.0928 - val_accuracy: 0.4494 - val_loss: 1.0949 - learning_rate: 3.0000e-04\n",
            "Epoch 34/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.4587 - loss: 1.0864 - val_accuracy: 0.4649 - val_loss: 1.0860 - learning_rate: 3.0000e-04\n",
            "Epoch 35/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 257ms/step - accuracy: 0.4523 - loss: 1.0884 - val_accuracy: 0.4503 - val_loss: 1.0876 - learning_rate: 3.0000e-04\n",
            "Epoch 36/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 263ms/step - accuracy: 0.4533 - loss: 1.0882 - val_accuracy: 0.4664 - val_loss: 1.0787 - learning_rate: 3.0000e-04\n",
            "Epoch 37/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 274ms/step - accuracy: 0.4609 - loss: 1.0774 - val_accuracy: 0.4551 - val_loss: 1.0807 - learning_rate: 3.0000e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 267ms/step - accuracy: 0.4619 - loss: 1.0789 - val_accuracy: 0.4678 - val_loss: 1.0696 - learning_rate: 3.0000e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.4624 - loss: 1.0717 - val_accuracy: 0.3904 - val_loss: 1.3838 - learning_rate: 3.0000e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 263ms/step - accuracy: 0.4649 - loss: 1.0674 - val_accuracy: 0.4500 - val_loss: 1.0708 - learning_rate: 3.0000e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 287ms/step - accuracy: 0.4636 - loss: 1.0691 - val_accuracy: 0.4633 - val_loss: 1.0669 - learning_rate: 3.0000e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.4652 - loss: 1.0606 - val_accuracy: 0.4669 - val_loss: 1.0569 - learning_rate: 3.0000e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.4628 - loss: 1.0660 - val_accuracy: 0.4593 - val_loss: 1.0629 - learning_rate: 3.0000e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 275ms/step - accuracy: 0.4688 - loss: 1.0573 - val_accuracy: 0.4631 - val_loss: 1.0602 - learning_rate: 3.0000e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 291ms/step - accuracy: 0.4661 - loss: 1.0609 - val_accuracy: 0.4576 - val_loss: 1.0633 - learning_rate: 3.0000e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 264ms/step - accuracy: 0.4656 - loss: 1.0623 - val_accuracy: 0.4680 - val_loss: 1.0582 - learning_rate: 3.0000e-04\n",
            "Epoch 47/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 268ms/step - accuracy: 0.4682 - loss: 1.0527 - val_accuracy: 0.4633 - val_loss: 1.0519 - learning_rate: 3.0000e-04\n",
            "Epoch 48/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 274ms/step - accuracy: 0.4674 - loss: 1.0499 - val_accuracy: 0.4729 - val_loss: 1.0460 - learning_rate: 3.0000e-04\n",
            "Epoch 49/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 264ms/step - accuracy: 0.4770 - loss: 1.0443 - val_accuracy: 0.4505 - val_loss: 1.0609 - learning_rate: 3.0000e-04\n",
            "Epoch 50/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 268ms/step - accuracy: 0.4633 - loss: 1.0513 - val_accuracy: 0.4689 - val_loss: 1.0472 - learning_rate: 3.0000e-04\n",
            "Epoch 51/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.4718 - loss: 1.0476 - val_accuracy: 0.4753 - val_loss: 1.0439 - learning_rate: 3.0000e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.4752 - loss: 1.0465 - val_accuracy: 0.4525 - val_loss: 1.0622 - learning_rate: 3.0000e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 280ms/step - accuracy: 0.4758 - loss: 1.0415 - val_accuracy: 0.4733 - val_loss: 1.0376 - learning_rate: 3.0000e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.4797 - loss: 1.0372 - val_accuracy: 0.4760 - val_loss: 1.0320 - learning_rate: 3.0000e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.4724 - loss: 1.0377 - val_accuracy: 0.4813 - val_loss: 1.0334 - learning_rate: 3.0000e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.4792 - loss: 1.0370 - val_accuracy: 0.4835 - val_loss: 1.0315 - learning_rate: 3.0000e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.4719 - loss: 1.0336 - val_accuracy: 0.4806 - val_loss: 1.0336 - learning_rate: 3.0000e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 268ms/step - accuracy: 0.4860 - loss: 1.0252 - val_accuracy: 0.4658 - val_loss: 1.0276 - learning_rate: 3.0000e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 277ms/step - accuracy: 0.4861 - loss: 1.0262 - val_accuracy: 0.4649 - val_loss: 1.0347 - learning_rate: 3.0000e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 267ms/step - accuracy: 0.4728 - loss: 1.0340 - val_accuracy: 0.4890 - val_loss: 1.0240 - learning_rate: 3.0000e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.4726 - loss: 1.0294 - val_accuracy: 0.4884 - val_loss: 1.0281 - learning_rate: 3.0000e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 258ms/step - accuracy: 0.4796 - loss: 1.0264 - val_accuracy: 0.4895 - val_loss: 1.0227 - learning_rate: 3.0000e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.4924 - loss: 1.0171 - val_accuracy: 0.4644 - val_loss: 1.0389 - learning_rate: 3.0000e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 255ms/step - accuracy: 0.4784 - loss: 1.0266 - val_accuracy: 0.4786 - val_loss: 1.0198 - learning_rate: 3.0000e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 264ms/step - accuracy: 0.4771 - loss: 1.0201 - val_accuracy: 0.4864 - val_loss: 1.0205 - learning_rate: 3.0000e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 261ms/step - accuracy: 0.4877 - loss: 1.0165 - val_accuracy: 0.4824 - val_loss: 1.0195 - learning_rate: 3.0000e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 266ms/step - accuracy: 0.4770 - loss: 1.0240 - val_accuracy: 0.4791 - val_loss: 1.0199 - learning_rate: 3.0000e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.4805 - loss: 1.0214 - val_accuracy: 0.4868 - val_loss: 1.0213 - learning_rate: 3.0000e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.4896 - loss: 1.0167 - val_accuracy: 0.4873 - val_loss: 1.0158 - learning_rate: 3.0000e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 275ms/step - accuracy: 0.4833 - loss: 1.0176 - val_accuracy: 0.4804 - val_loss: 1.0194 - learning_rate: 3.0000e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.4885 - loss: 1.0093 - val_accuracy: 0.4819 - val_loss: 1.0216 - learning_rate: 3.0000e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.4986 - loss: 1.0042 - val_accuracy: 0.4822 - val_loss: 1.0292 - learning_rate: 3.0000e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.4934 - loss: 1.0058 - val_accuracy: 0.4802 - val_loss: 1.0118 - learning_rate: 3.0000e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.4849 - loss: 1.0132 - val_accuracy: 0.4862 - val_loss: 1.0100 - learning_rate: 3.0000e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.4887 - loss: 1.0086 - val_accuracy: 0.4826 - val_loss: 1.0014 - learning_rate: 3.0000e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 266ms/step - accuracy: 0.4984 - loss: 0.9989 - val_accuracy: 0.4912 - val_loss: 1.0071 - learning_rate: 3.0000e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.4958 - loss: 1.0008 - val_accuracy: 0.4604 - val_loss: 1.0260 - learning_rate: 3.0000e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 264ms/step - accuracy: 0.4940 - loss: 0.9961 - val_accuracy: 0.4928 - val_loss: 1.0091 - learning_rate: 3.0000e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 265ms/step - accuracy: 0.4955 - loss: 1.0030 - val_accuracy: 0.4946 - val_loss: 0.9972 - learning_rate: 3.0000e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.4919 - loss: 1.0013 - val_accuracy: 0.4862 - val_loss: 1.0063 - learning_rate: 3.0000e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.4894 - loss: 1.0036 - val_accuracy: 0.4941 - val_loss: 0.9985 - learning_rate: 3.0000e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.5030 - loss: 0.9912 - val_accuracy: 0.4859 - val_loss: 1.0028 - learning_rate: 3.0000e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5033 - loss: 0.9949 - val_accuracy: 0.4853 - val_loss: 1.0018 - learning_rate: 3.0000e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.4976 - loss: 0.9917 - val_accuracy: 0.4859 - val_loss: 1.0026 - learning_rate: 3.0000e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 275ms/step - accuracy: 0.4953 - loss: 0.9989 - val_accuracy: 0.4955 - val_loss: 0.9954 - learning_rate: 3.0000e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 267ms/step - accuracy: 0.4930 - loss: 0.9964 - val_accuracy: 0.4824 - val_loss: 1.0114 - learning_rate: 3.0000e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 265ms/step - accuracy: 0.5032 - loss: 0.9874 - val_accuracy: 0.4930 - val_loss: 0.9972 - learning_rate: 3.0000e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 258ms/step - accuracy: 0.4961 - loss: 0.9957 - val_accuracy: 0.5030 - val_loss: 0.9945 - learning_rate: 3.0000e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 277ms/step - accuracy: 0.5058 - loss: 0.9879 - val_accuracy: 0.4844 - val_loss: 1.0063 - learning_rate: 3.0000e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.4978 - loss: 0.9917 - val_accuracy: 0.4857 - val_loss: 0.9972 - learning_rate: 3.0000e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 267ms/step - accuracy: 0.5081 - loss: 0.9816 - val_accuracy: 0.4904 - val_loss: 1.0015 - learning_rate: 3.0000e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5008 - loss: 0.9905 - val_accuracy: 0.5039 - val_loss: 0.9952 - learning_rate: 3.0000e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.4955 - loss: 0.9929 - val_accuracy: 0.4924 - val_loss: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.5006 - loss: 0.9913 - val_accuracy: 0.5014 - val_loss: 0.9975 - learning_rate: 3.0000e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.5048 - loss: 0.9864 - val_accuracy: 0.4928 - val_loss: 0.9938 - learning_rate: 3.0000e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.5091 - loss: 0.9805 - val_accuracy: 0.5085 - val_loss: 0.9850 - learning_rate: 3.0000e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5121 - loss: 0.9787 - val_accuracy: 0.5006 - val_loss: 0.9971 - learning_rate: 3.0000e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 265ms/step - accuracy: 0.5062 - loss: 0.9753 - val_accuracy: 0.5138 - val_loss: 0.9760 - learning_rate: 3.0000e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.5073 - loss: 0.9716 - val_accuracy: 0.5023 - val_loss: 0.9799 - learning_rate: 3.0000e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.5142 - loss: 0.9687 - val_accuracy: 0.5085 - val_loss: 0.9792 - learning_rate: 3.0000e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.5139 - loss: 0.9801 - val_accuracy: 0.5059 - val_loss: 0.9824 - learning_rate: 3.0000e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.5120 - loss: 0.9747 - val_accuracy: 0.5063 - val_loss: 0.9813 - learning_rate: 3.0000e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 278ms/step - accuracy: 0.5147 - loss: 0.9715 - val_accuracy: 0.5103 - val_loss: 0.9821 - learning_rate: 3.0000e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 264ms/step - accuracy: 0.5081 - loss: 0.9710 - val_accuracy: 0.5008 - val_loss: 0.9886 - learning_rate: 3.0000e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.5192 - loss: 0.9692 - val_accuracy: 0.5021 - val_loss: 0.9858 - learning_rate: 3.0000e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 264ms/step - accuracy: 0.5105 - loss: 0.9766 - val_accuracy: 0.5150 - val_loss: 0.9755 - learning_rate: 3.0000e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 276ms/step - accuracy: 0.5219 - loss: 0.9659 - val_accuracy: 0.5152 - val_loss: 0.9745 - learning_rate: 3.0000e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5114 - loss: 0.9703 - val_accuracy: 0.5065 - val_loss: 0.9846 - learning_rate: 3.0000e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5136 - loss: 0.9702 - val_accuracy: 0.4941 - val_loss: 0.9935 - learning_rate: 3.0000e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 264ms/step - accuracy: 0.5170 - loss: 0.9627 - val_accuracy: 0.5125 - val_loss: 0.9749 - learning_rate: 3.0000e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.5075 - loss: 0.9794 - val_accuracy: 0.5119 - val_loss: 0.9833 - learning_rate: 3.0000e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.5138 - loss: 0.9638 - val_accuracy: 0.5119 - val_loss: 0.9756 - learning_rate: 3.0000e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 266ms/step - accuracy: 0.5162 - loss: 0.9652 - val_accuracy: 0.5037 - val_loss: 0.9858 - learning_rate: 3.0000e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 270ms/step - accuracy: 0.5176 - loss: 0.9669 - val_accuracy: 0.5154 - val_loss: 0.9704 - learning_rate: 3.0000e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5172 - loss: 0.9730 - val_accuracy: 0.5072 - val_loss: 0.9769 - learning_rate: 3.0000e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5196 - loss: 0.9618 - val_accuracy: 0.5201 - val_loss: 0.9755 - learning_rate: 3.0000e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.5146 - loss: 0.9713 - val_accuracy: 0.5096 - val_loss: 0.9742 - learning_rate: 3.0000e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 291ms/step - accuracy: 0.5220 - loss: 0.9641 - val_accuracy: 0.5134 - val_loss: 0.9722 - learning_rate: 3.0000e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.5197 - loss: 0.9674 - val_accuracy: 0.5068 - val_loss: 0.9812 - learning_rate: 3.0000e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 264ms/step - accuracy: 0.5283 - loss: 0.9568 - val_accuracy: 0.5107 - val_loss: 0.9752 - learning_rate: 3.0000e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 266ms/step - accuracy: 0.5273 - loss: 0.9631 - val_accuracy: 0.5198 - val_loss: 0.9757 - learning_rate: 3.0000e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.5357 - loss: 0.9512 - val_accuracy: 0.5327 - val_loss: 0.9627 - learning_rate: 3.0000e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.5323 - loss: 0.9490 - val_accuracy: 0.5119 - val_loss: 0.9755 - learning_rate: 3.0000e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 261ms/step - accuracy: 0.5239 - loss: 0.9623 - val_accuracy: 0.5154 - val_loss: 0.9698 - learning_rate: 3.0000e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.5332 - loss: 0.9500 - val_accuracy: 0.5218 - val_loss: 0.9710 - learning_rate: 3.0000e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.5219 - loss: 0.9596 - val_accuracy: 0.5289 - val_loss: 0.9645 - learning_rate: 3.0000e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 278ms/step - accuracy: 0.5205 - loss: 0.9537 - val_accuracy: 0.5311 - val_loss: 0.9630 - learning_rate: 3.0000e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5298 - loss: 0.9473 - val_accuracy: 0.5243 - val_loss: 0.9599 - learning_rate: 3.0000e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.5374 - loss: 0.9355 - val_accuracy: 0.5274 - val_loss: 0.9659 - learning_rate: 3.0000e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 280ms/step - accuracy: 0.5231 - loss: 0.9544 - val_accuracy: 0.5280 - val_loss: 0.9594 - learning_rate: 3.0000e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.5311 - loss: 0.9418 - val_accuracy: 0.5351 - val_loss: 0.9604 - learning_rate: 3.0000e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.5333 - loss: 0.9457 - val_accuracy: 0.5309 - val_loss: 0.9593 - learning_rate: 3.0000e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 279ms/step - accuracy: 0.5324 - loss: 0.9487 - val_accuracy: 0.5314 - val_loss: 0.9649 - learning_rate: 3.0000e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 264ms/step - accuracy: 0.5343 - loss: 0.9418 - val_accuracy: 0.5194 - val_loss: 0.9588 - learning_rate: 3.0000e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 257ms/step - accuracy: 0.5334 - loss: 0.9410 - val_accuracy: 0.5325 - val_loss: 0.9535 - learning_rate: 3.0000e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.5390 - loss: 0.9407 - val_accuracy: 0.5247 - val_loss: 0.9597 - learning_rate: 3.0000e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 272ms/step - accuracy: 0.5460 - loss: 0.9354 - val_accuracy: 0.5278 - val_loss: 0.9556 - learning_rate: 3.0000e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 276ms/step - accuracy: 0.5315 - loss: 0.9477 - val_accuracy: 0.5320 - val_loss: 0.9555 - learning_rate: 3.0000e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 265ms/step - accuracy: 0.5365 - loss: 0.9384 - val_accuracy: 0.5291 - val_loss: 0.9554 - learning_rate: 3.0000e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.5385 - loss: 0.9377 - val_accuracy: 0.5258 - val_loss: 0.9594 - learning_rate: 3.0000e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.5444 - loss: 0.9350 - val_accuracy: 0.5130 - val_loss: 0.9682 - learning_rate: 3.0000e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5421 - loss: 0.9299 - val_accuracy: 0.5223 - val_loss: 0.9518 - learning_rate: 3.0000e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.5394 - loss: 0.9363 - val_accuracy: 0.5347 - val_loss: 0.9453 - learning_rate: 3.0000e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5470 - loss: 0.9331 - val_accuracy: 0.5314 - val_loss: 0.9445 - learning_rate: 3.0000e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.5509 - loss: 0.9203 - val_accuracy: 0.5285 - val_loss: 0.9524 - learning_rate: 3.0000e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.5515 - loss: 0.9232 - val_accuracy: 0.5280 - val_loss: 0.9476 - learning_rate: 3.0000e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5501 - loss: 0.9261 - val_accuracy: 0.5280 - val_loss: 0.9595 - learning_rate: 3.0000e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.5381 - loss: 0.9358 - val_accuracy: 0.5340 - val_loss: 0.9535 - learning_rate: 3.0000e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5494 - loss: 0.9220 - val_accuracy: 0.5351 - val_loss: 0.9428 - learning_rate: 3.0000e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5458 - loss: 0.9230 - val_accuracy: 0.5367 - val_loss: 0.9401 - learning_rate: 3.0000e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 266ms/step - accuracy: 0.5553 - loss: 0.9178 - val_accuracy: 0.5309 - val_loss: 0.9445 - learning_rate: 3.0000e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.5498 - loss: 0.9278 - val_accuracy: 0.5251 - val_loss: 0.9563 - learning_rate: 3.0000e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 284ms/step - accuracy: 0.5470 - loss: 0.9264 - val_accuracy: 0.5302 - val_loss: 0.9402 - learning_rate: 3.0000e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.5438 - loss: 0.9254 - val_accuracy: 0.5420 - val_loss: 0.9407 - learning_rate: 3.0000e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.5556 - loss: 0.9151 - val_accuracy: 0.5338 - val_loss: 0.9474 - learning_rate: 3.0000e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.5496 - loss: 0.9223 - val_accuracy: 0.5398 - val_loss: 0.9392 - learning_rate: 3.0000e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.5448 - loss: 0.9286 - val_accuracy: 0.5305 - val_loss: 0.9513 - learning_rate: 3.0000e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.5548 - loss: 0.9190 - val_accuracy: 0.5451 - val_loss: 0.9345 - learning_rate: 3.0000e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5620 - loss: 0.9074 - val_accuracy: 0.5360 - val_loss: 0.9472 - learning_rate: 3.0000e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.5660 - loss: 0.9046 - val_accuracy: 0.5358 - val_loss: 0.9368 - learning_rate: 3.0000e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.5614 - loss: 0.9076 - val_accuracy: 0.5433 - val_loss: 0.9370 - learning_rate: 3.0000e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.5639 - loss: 0.8980 - val_accuracy: 0.5480 - val_loss: 0.9361 - learning_rate: 3.0000e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.5604 - loss: 0.9106 - val_accuracy: 0.5431 - val_loss: 0.9347 - learning_rate: 3.0000e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 276ms/step - accuracy: 0.5697 - loss: 0.9058 - val_accuracy: 0.5482 - val_loss: 0.9340 - learning_rate: 3.0000e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.5638 - loss: 0.9030 - val_accuracy: 0.5475 - val_loss: 0.9352 - learning_rate: 3.0000e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5612 - loss: 0.9084 - val_accuracy: 0.5429 - val_loss: 0.9370 - learning_rate: 3.0000e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.5574 - loss: 0.9093 - val_accuracy: 0.5455 - val_loss: 0.9234 - learning_rate: 3.0000e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 265ms/step - accuracy: 0.5726 - loss: 0.8957 - val_accuracy: 0.5546 - val_loss: 0.9219 - learning_rate: 3.0000e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 267ms/step - accuracy: 0.5717 - loss: 0.8920 - val_accuracy: 0.5509 - val_loss: 0.9343 - learning_rate: 3.0000e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 265ms/step - accuracy: 0.5634 - loss: 0.9038 - val_accuracy: 0.5449 - val_loss: 0.9251 - learning_rate: 3.0000e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.5601 - loss: 0.9069 - val_accuracy: 0.5559 - val_loss: 0.9209 - learning_rate: 3.0000e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 270ms/step - accuracy: 0.5721 - loss: 0.8943 - val_accuracy: 0.5444 - val_loss: 0.9267 - learning_rate: 3.0000e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.5554 - loss: 0.9094 - val_accuracy: 0.5287 - val_loss: 0.9449 - learning_rate: 3.0000e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.5628 - loss: 0.9026 - val_accuracy: 0.5453 - val_loss: 0.9292 - learning_rate: 3.0000e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 280ms/step - accuracy: 0.5744 - loss: 0.8933 - val_accuracy: 0.5480 - val_loss: 0.9311 - learning_rate: 3.0000e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.5687 - loss: 0.8950 - val_accuracy: 0.5493 - val_loss: 0.9249 - learning_rate: 3.0000e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 266ms/step - accuracy: 0.5736 - loss: 0.8858 - val_accuracy: 0.5517 - val_loss: 0.9223 - learning_rate: 3.0000e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 259ms/step - accuracy: 0.5733 - loss: 0.8869 - val_accuracy: 0.5486 - val_loss: 0.9196 - learning_rate: 3.0000e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 275ms/step - accuracy: 0.5719 - loss: 0.8920 - val_accuracy: 0.5540 - val_loss: 0.9218 - learning_rate: 3.0000e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.5824 - loss: 0.8874 - val_accuracy: 0.5613 - val_loss: 0.9160 - learning_rate: 3.0000e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.5792 - loss: 0.8864 - val_accuracy: 0.5553 - val_loss: 0.9176 - learning_rate: 3.0000e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 278ms/step - accuracy: 0.5826 - loss: 0.8797 - val_accuracy: 0.5648 - val_loss: 0.9131 - learning_rate: 3.0000e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.5737 - loss: 0.8928 - val_accuracy: 0.5639 - val_loss: 0.9157 - learning_rate: 3.0000e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.5743 - loss: 0.8942 - val_accuracy: 0.5657 - val_loss: 0.9150 - learning_rate: 3.0000e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.5756 - loss: 0.8864 - val_accuracy: 0.5593 - val_loss: 0.9120 - learning_rate: 3.0000e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.5750 - loss: 0.8884 - val_accuracy: 0.5606 - val_loss: 0.9182 - learning_rate: 3.0000e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.5769 - loss: 0.8780 - val_accuracy: 0.5661 - val_loss: 0.9102 - learning_rate: 3.0000e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.5810 - loss: 0.8813 - val_accuracy: 0.5659 - val_loss: 0.9147 - learning_rate: 3.0000e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.5807 - loss: 0.8757 - val_accuracy: 0.5588 - val_loss: 0.9193 - learning_rate: 3.0000e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.5864 - loss: 0.8789 - val_accuracy: 0.5679 - val_loss: 0.9089 - learning_rate: 3.0000e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.5976 - loss: 0.8561 - val_accuracy: 0.5646 - val_loss: 0.9125 - learning_rate: 3.0000e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.5889 - loss: 0.8659 - val_accuracy: 0.5690 - val_loss: 0.9100 - learning_rate: 3.0000e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 289ms/step - accuracy: 0.5786 - loss: 0.8778 - val_accuracy: 0.5743 - val_loss: 0.9038 - learning_rate: 3.0000e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.5832 - loss: 0.8708 - val_accuracy: 0.5653 - val_loss: 0.9091 - learning_rate: 3.0000e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 271ms/step - accuracy: 0.5886 - loss: 0.8685 - val_accuracy: 0.5637 - val_loss: 0.9062 - learning_rate: 3.0000e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.5969 - loss: 0.8505 - val_accuracy: 0.5666 - val_loss: 0.9073 - learning_rate: 3.0000e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5821 - loss: 0.8819 - val_accuracy: 0.5644 - val_loss: 0.9122 - learning_rate: 3.0000e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.5692 - loss: 0.8921 - val_accuracy: 0.5513 - val_loss: 0.9209 - learning_rate: 3.0000e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5956 - loss: 0.8650 - val_accuracy: 0.5646 - val_loss: 0.9081 - learning_rate: 3.0000e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5922 - loss: 0.8599 - val_accuracy: 0.5730 - val_loss: 0.9061 - learning_rate: 3.0000e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.5928 - loss: 0.8602 - val_accuracy: 0.5699 - val_loss: 0.9047 - learning_rate: 3.0000e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 267ms/step - accuracy: 0.6017 - loss: 0.8541 - val_accuracy: 0.5692 - val_loss: 0.9025 - learning_rate: 3.0000e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 271ms/step - accuracy: 0.5828 - loss: 0.8682 - val_accuracy: 0.5690 - val_loss: 0.9031 - learning_rate: 3.0000e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.5956 - loss: 0.8577 - val_accuracy: 0.5768 - val_loss: 0.9047 - learning_rate: 3.0000e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.5860 - loss: 0.8681 - val_accuracy: 0.5664 - val_loss: 0.8978 - learning_rate: 3.0000e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.5955 - loss: 0.8550 - val_accuracy: 0.5710 - val_loss: 0.8975 - learning_rate: 3.0000e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 267ms/step - accuracy: 0.5948 - loss: 0.8681 - val_accuracy: 0.5679 - val_loss: 0.8944 - learning_rate: 3.0000e-04\n",
            "Epoch 208/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 277ms/step - accuracy: 0.5835 - loss: 0.8632 - val_accuracy: 0.5770 - val_loss: 0.8970 - learning_rate: 3.0000e-04\n",
            "Epoch 209/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.6008 - loss: 0.8543 - val_accuracy: 0.5783 - val_loss: 0.8965 - learning_rate: 3.0000e-04\n",
            "Epoch 210/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6012 - loss: 0.8462 - val_accuracy: 0.5706 - val_loss: 0.8994 - learning_rate: 3.0000e-04\n",
            "Epoch 211/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.5965 - loss: 0.8525 - val_accuracy: 0.5717 - val_loss: 0.9059 - learning_rate: 3.0000e-04\n",
            "Epoch 212/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.5992 - loss: 0.8475 - val_accuracy: 0.5812 - val_loss: 0.8972 - learning_rate: 3.0000e-04\n",
            "Epoch 213/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 271ms/step - accuracy: 0.6055 - loss: 0.8392 - val_accuracy: 0.5859 - val_loss: 0.9046 - learning_rate: 3.0000e-04\n",
            "Epoch 214/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.6067 - loss: 0.8443 - val_accuracy: 0.5894 - val_loss: 0.8887 - learning_rate: 3.0000e-04\n",
            "Epoch 215/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 271ms/step - accuracy: 0.6027 - loss: 0.8501 - val_accuracy: 0.5845 - val_loss: 0.8983 - learning_rate: 3.0000e-04\n",
            "Epoch 216/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 281ms/step - accuracy: 0.6096 - loss: 0.8312 - val_accuracy: 0.5936 - val_loss: 0.8923 - learning_rate: 3.0000e-04\n",
            "Epoch 217/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6026 - loss: 0.8408 - val_accuracy: 0.5841 - val_loss: 0.8948 - learning_rate: 3.0000e-04\n",
            "Epoch 218/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.6045 - loss: 0.8367 - val_accuracy: 0.5812 - val_loss: 0.8993 - learning_rate: 3.0000e-04\n",
            "Epoch 219/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 262ms/step - accuracy: 0.6016 - loss: 0.8423 - val_accuracy: 0.5803 - val_loss: 0.8942 - learning_rate: 3.0000e-04\n",
            "Epoch 220/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.6109 - loss: 0.8367 - val_accuracy: 0.5792 - val_loss: 0.9036 - learning_rate: 3.0000e-04\n",
            "Epoch 221/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 261ms/step - accuracy: 0.6075 - loss: 0.8353 - val_accuracy: 0.5803 - val_loss: 0.8891 - learning_rate: 3.0000e-04\n",
            "Epoch 222/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 268ms/step - accuracy: 0.6068 - loss: 0.8447 - val_accuracy: 0.5832 - val_loss: 0.8918 - learning_rate: 3.0000e-04\n",
            "Epoch 223/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.6128 - loss: 0.8347 - val_accuracy: 0.5792 - val_loss: 0.8890 - learning_rate: 3.0000e-04\n",
            "Epoch 224/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.6074 - loss: 0.8422 - val_accuracy: 0.5834 - val_loss: 0.8853 - learning_rate: 3.0000e-04\n",
            "Epoch 225/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 267ms/step - accuracy: 0.6151 - loss: 0.8300 - val_accuracy: 0.5832 - val_loss: 0.8837 - learning_rate: 3.0000e-04\n",
            "Epoch 226/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.6167 - loss: 0.8244 - val_accuracy: 0.5852 - val_loss: 0.8769 - learning_rate: 3.0000e-04\n",
            "Epoch 227/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.6110 - loss: 0.8379 - val_accuracy: 0.5792 - val_loss: 0.8888 - learning_rate: 3.0000e-04\n",
            "Epoch 228/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 272ms/step - accuracy: 0.6107 - loss: 0.8341 - val_accuracy: 0.5814 - val_loss: 0.8845 - learning_rate: 3.0000e-04\n",
            "Epoch 229/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 267ms/step - accuracy: 0.6138 - loss: 0.8276 - val_accuracy: 0.5821 - val_loss: 0.9006 - learning_rate: 3.0000e-04\n",
            "Epoch 230/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 272ms/step - accuracy: 0.6128 - loss: 0.8366 - val_accuracy: 0.5894 - val_loss: 0.8765 - learning_rate: 3.0000e-04\n",
            "Epoch 231/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 282ms/step - accuracy: 0.6216 - loss: 0.8155 - val_accuracy: 0.5757 - val_loss: 0.8969 - learning_rate: 3.0000e-04\n",
            "Epoch 232/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.6172 - loss: 0.8250 - val_accuracy: 0.5861 - val_loss: 0.8815 - learning_rate: 3.0000e-04\n",
            "Epoch 233/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 267ms/step - accuracy: 0.6205 - loss: 0.8226 - val_accuracy: 0.5883 - val_loss: 0.8809 - learning_rate: 3.0000e-04\n",
            "Epoch 234/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 277ms/step - accuracy: 0.6214 - loss: 0.8184 - val_accuracy: 0.5961 - val_loss: 0.8733 - learning_rate: 3.0000e-04\n",
            "Epoch 235/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.6259 - loss: 0.8140 - val_accuracy: 0.5872 - val_loss: 0.8924 - learning_rate: 3.0000e-04\n",
            "Epoch 236/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 267ms/step - accuracy: 0.6166 - loss: 0.8249 - val_accuracy: 0.5834 - val_loss: 0.8878 - learning_rate: 3.0000e-04\n",
            "Epoch 237/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.6210 - loss: 0.8104 - val_accuracy: 0.5916 - val_loss: 0.8810 - learning_rate: 3.0000e-04\n",
            "Epoch 238/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.6305 - loss: 0.8045 - val_accuracy: 0.5996 - val_loss: 0.8669 - learning_rate: 3.0000e-04\n",
            "Epoch 239/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.6152 - loss: 0.8345 - val_accuracy: 0.5972 - val_loss: 0.8716 - learning_rate: 3.0000e-04\n",
            "Epoch 240/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6168 - loss: 0.8144 - val_accuracy: 0.5996 - val_loss: 0.8782 - learning_rate: 3.0000e-04\n",
            "Epoch 241/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6296 - loss: 0.8063 - val_accuracy: 0.5910 - val_loss: 0.8731 - learning_rate: 3.0000e-04\n",
            "Epoch 242/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 282ms/step - accuracy: 0.6249 - loss: 0.8115 - val_accuracy: 0.6000 - val_loss: 0.8675 - learning_rate: 3.0000e-04\n",
            "Epoch 243/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6344 - loss: 0.8023 - val_accuracy: 0.5872 - val_loss: 0.8788 - learning_rate: 3.0000e-04\n",
            "Epoch 244/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6348 - loss: 0.7960 - val_accuracy: 0.5978 - val_loss: 0.8769 - learning_rate: 3.0000e-04\n",
            "Epoch 245/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.6336 - loss: 0.7950 - val_accuracy: 0.6054 - val_loss: 0.8730 - learning_rate: 3.0000e-04\n",
            "Epoch 246/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.6277 - loss: 0.8031 - val_accuracy: 0.5952 - val_loss: 0.8781 - learning_rate: 3.0000e-04\n",
            "Epoch 247/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.6330 - loss: 0.7979 - val_accuracy: 0.5985 - val_loss: 0.8697 - learning_rate: 3.0000e-04\n",
            "Epoch 248/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.6341 - loss: 0.7990 - val_accuracy: 0.6051 - val_loss: 0.8694 - learning_rate: 3.0000e-04\n",
            "Epoch 249/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 278ms/step - accuracy: 0.6460 - loss: 0.7859 - val_accuracy: 0.5934 - val_loss: 0.8767 - learning_rate: 3.0000e-04\n",
            "Epoch 250/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.6354 - loss: 0.7927 - val_accuracy: 0.5983 - val_loss: 0.8638 - learning_rate: 3.0000e-04\n",
            "Epoch 251/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.6270 - loss: 0.8049 - val_accuracy: 0.5992 - val_loss: 0.8719 - learning_rate: 3.0000e-04\n",
            "Epoch 252/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 261ms/step - accuracy: 0.6378 - loss: 0.7952 - val_accuracy: 0.5925 - val_loss: 0.8766 - learning_rate: 3.0000e-04\n",
            "Epoch 253/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 282ms/step - accuracy: 0.6371 - loss: 0.7991 - val_accuracy: 0.5916 - val_loss: 0.8750 - learning_rate: 3.0000e-04\n",
            "Epoch 254/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6322 - loss: 0.7994 - val_accuracy: 0.5956 - val_loss: 0.8762 - learning_rate: 3.0000e-04\n",
            "Epoch 255/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6302 - loss: 0.8015 - val_accuracy: 0.5874 - val_loss: 0.8821 - learning_rate: 3.0000e-04\n",
            "Epoch 256/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.6337 - loss: 0.7925 - val_accuracy: 0.6014 - val_loss: 0.8780 - learning_rate: 3.0000e-04\n",
            "Epoch 257/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 281ms/step - accuracy: 0.6377 - loss: 0.7879 - val_accuracy: 0.6054 - val_loss: 0.8665 - learning_rate: 3.0000e-04\n",
            "Epoch 258/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.6413 - loss: 0.7872 - val_accuracy: 0.6082 - val_loss: 0.8576 - learning_rate: 3.0000e-04\n",
            "Epoch 259/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6456 - loss: 0.7811 - val_accuracy: 0.6043 - val_loss: 0.8646 - learning_rate: 3.0000e-04\n",
            "Epoch 260/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 278ms/step - accuracy: 0.6328 - loss: 0.7989 - val_accuracy: 0.5947 - val_loss: 0.8779 - learning_rate: 3.0000e-04\n",
            "Epoch 261/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 268ms/step - accuracy: 0.6388 - loss: 0.7946 - val_accuracy: 0.5943 - val_loss: 0.8774 - learning_rate: 3.0000e-04\n",
            "Epoch 262/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.6393 - loss: 0.7900 - val_accuracy: 0.5947 - val_loss: 0.8770 - learning_rate: 3.0000e-04\n",
            "Epoch 263/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.6430 - loss: 0.7861 - val_accuracy: 0.5998 - val_loss: 0.8703 - learning_rate: 3.0000e-04\n",
            "Epoch 264/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.6462 - loss: 0.7759 - val_accuracy: 0.6062 - val_loss: 0.8710 - learning_rate: 3.0000e-04\n",
            "Epoch 265/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 269ms/step - accuracy: 0.6384 - loss: 0.7892 - val_accuracy: 0.6036 - val_loss: 0.8770 - learning_rate: 3.0000e-04\n",
            "Epoch 266/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 274ms/step - accuracy: 0.6502 - loss: 0.7787 - val_accuracy: 0.6027 - val_loss: 0.8786 - learning_rate: 3.0000e-04\n",
            "Epoch 267/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 269ms/step - accuracy: 0.6383 - loss: 0.7786 - val_accuracy: 0.5958 - val_loss: 0.8704 - learning_rate: 3.0000e-04\n",
            "Epoch 268/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.6424 - loss: 0.7817 - val_accuracy: 0.5952 - val_loss: 0.8650 - learning_rate: 3.0000e-04\n",
            "Epoch 269/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6435 - loss: 0.7855 - val_accuracy: 0.5992 - val_loss: 0.8807 - learning_rate: 3.0000e-04\n",
            "Epoch 270/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.6439 - loss: 0.7820 - val_accuracy: 0.6049 - val_loss: 0.8639 - learning_rate: 3.0000e-04\n",
            "Epoch 271/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 281ms/step - accuracy: 0.6494 - loss: 0.7691 - val_accuracy: 0.6113 - val_loss: 0.8511 - learning_rate: 1.5000e-04\n",
            "Epoch 272/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 269ms/step - accuracy: 0.6601 - loss: 0.7472 - val_accuracy: 0.6222 - val_loss: 0.8420 - learning_rate: 1.5000e-04\n",
            "Epoch 273/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6673 - loss: 0.7442 - val_accuracy: 0.6195 - val_loss: 0.8391 - learning_rate: 1.5000e-04\n",
            "Epoch 274/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.6636 - loss: 0.7474 - val_accuracy: 0.6218 - val_loss: 0.8462 - learning_rate: 1.5000e-04\n",
            "Epoch 275/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.6693 - loss: 0.7382 - val_accuracy: 0.6200 - val_loss: 0.8515 - learning_rate: 1.5000e-04\n",
            "Epoch 276/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6689 - loss: 0.7375 - val_accuracy: 0.6209 - val_loss: 0.8477 - learning_rate: 1.5000e-04\n",
            "Epoch 277/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.6758 - loss: 0.7218 - val_accuracy: 0.6207 - val_loss: 0.8480 - learning_rate: 1.5000e-04\n",
            "Epoch 278/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6712 - loss: 0.7379 - val_accuracy: 0.6184 - val_loss: 0.8416 - learning_rate: 1.5000e-04\n",
            "Epoch 279/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 283ms/step - accuracy: 0.6774 - loss: 0.7280 - val_accuracy: 0.6164 - val_loss: 0.8507 - learning_rate: 1.5000e-04\n",
            "Epoch 280/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 274ms/step - accuracy: 0.6799 - loss: 0.7337 - val_accuracy: 0.6284 - val_loss: 0.8384 - learning_rate: 1.5000e-04\n",
            "Epoch 281/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 275ms/step - accuracy: 0.6751 - loss: 0.7333 - val_accuracy: 0.6284 - val_loss: 0.8366 - learning_rate: 1.5000e-04\n",
            "Epoch 282/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.6817 - loss: 0.7220 - val_accuracy: 0.6333 - val_loss: 0.8387 - learning_rate: 1.5000e-04\n",
            "Epoch 283/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.6745 - loss: 0.7319 - val_accuracy: 0.6200 - val_loss: 0.8390 - learning_rate: 1.5000e-04\n",
            "Epoch 284/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.6857 - loss: 0.7170 - val_accuracy: 0.6200 - val_loss: 0.8410 - learning_rate: 1.5000e-04\n",
            "Epoch 285/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6828 - loss: 0.7132 - val_accuracy: 0.6253 - val_loss: 0.8416 - learning_rate: 1.5000e-04\n",
            "Epoch 286/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 280ms/step - accuracy: 0.6804 - loss: 0.7226 - val_accuracy: 0.6262 - val_loss: 0.8355 - learning_rate: 1.5000e-04\n",
            "Epoch 287/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.6786 - loss: 0.7212 - val_accuracy: 0.6297 - val_loss: 0.8360 - learning_rate: 1.5000e-04\n",
            "Epoch 288/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 264ms/step - accuracy: 0.6806 - loss: 0.7159 - val_accuracy: 0.6222 - val_loss: 0.8406 - learning_rate: 1.5000e-04\n",
            "Epoch 289/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 286ms/step - accuracy: 0.6781 - loss: 0.7208 - val_accuracy: 0.6313 - val_loss: 0.8450 - learning_rate: 1.5000e-04\n",
            "Epoch 290/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 283ms/step - accuracy: 0.6726 - loss: 0.7318 - val_accuracy: 0.6351 - val_loss: 0.8393 - learning_rate: 1.5000e-04\n",
            "Epoch 291/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.6874 - loss: 0.7120 - val_accuracy: 0.6275 - val_loss: 0.8379 - learning_rate: 1.5000e-04\n",
            "Epoch 292/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.6854 - loss: 0.7093 - val_accuracy: 0.6297 - val_loss: 0.8385 - learning_rate: 1.5000e-04\n",
            "Epoch 293/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.6918 - loss: 0.6997 - val_accuracy: 0.6375 - val_loss: 0.8261 - learning_rate: 1.5000e-04\n",
            "Epoch 294/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 270ms/step - accuracy: 0.6827 - loss: 0.7027 - val_accuracy: 0.6348 - val_loss: 0.8348 - learning_rate: 1.5000e-04\n",
            "Epoch 295/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.6770 - loss: 0.7133 - val_accuracy: 0.6324 - val_loss: 0.8321 - learning_rate: 1.5000e-04\n",
            "Epoch 296/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.6867 - loss: 0.7009 - val_accuracy: 0.6308 - val_loss: 0.8284 - learning_rate: 1.5000e-04\n",
            "Epoch 297/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.6881 - loss: 0.6992 - val_accuracy: 0.6377 - val_loss: 0.8292 - learning_rate: 1.5000e-04\n",
            "Epoch 298/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 265ms/step - accuracy: 0.6907 - loss: 0.7048 - val_accuracy: 0.6333 - val_loss: 0.8315 - learning_rate: 1.5000e-04\n",
            "Epoch 299/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6952 - loss: 0.6936 - val_accuracy: 0.6295 - val_loss: 0.8370 - learning_rate: 1.5000e-04\n",
            "Epoch 300/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.6984 - loss: 0.7059 - val_accuracy: 0.6355 - val_loss: 0.8357 - learning_rate: 1.5000e-04\n",
            "Epoch 301/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.6923 - loss: 0.6961 - val_accuracy: 0.6260 - val_loss: 0.8362 - learning_rate: 1.5000e-04\n",
            "Epoch 302/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.6898 - loss: 0.6981 - val_accuracy: 0.6271 - val_loss: 0.8363 - learning_rate: 1.5000e-04\n",
            "Epoch 303/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.6862 - loss: 0.7028 - val_accuracy: 0.6346 - val_loss: 0.8317 - learning_rate: 1.5000e-04\n",
            "Epoch 304/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 291ms/step - accuracy: 0.6884 - loss: 0.6986 - val_accuracy: 0.6351 - val_loss: 0.8335 - learning_rate: 1.5000e-04\n",
            "Epoch 305/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.6952 - loss: 0.6917 - val_accuracy: 0.6406 - val_loss: 0.8301 - learning_rate: 1.5000e-04\n",
            "Epoch 306/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 269ms/step - accuracy: 0.6901 - loss: 0.6906 - val_accuracy: 0.6399 - val_loss: 0.8222 - learning_rate: 7.5000e-05\n",
            "Epoch 307/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 270ms/step - accuracy: 0.6983 - loss: 0.6816 - val_accuracy: 0.6417 - val_loss: 0.8245 - learning_rate: 7.5000e-05\n",
            "Epoch 308/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.7008 - loss: 0.6808 - val_accuracy: 0.6428 - val_loss: 0.8167 - learning_rate: 7.5000e-05\n",
            "Epoch 309/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 267ms/step - accuracy: 0.7019 - loss: 0.6800 - val_accuracy: 0.6382 - val_loss: 0.8213 - learning_rate: 7.5000e-05\n",
            "Epoch 310/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 268ms/step - accuracy: 0.7056 - loss: 0.6679 - val_accuracy: 0.6439 - val_loss: 0.8206 - learning_rate: 7.5000e-05\n",
            "Epoch 311/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.7040 - loss: 0.6773 - val_accuracy: 0.6346 - val_loss: 0.8220 - learning_rate: 7.5000e-05\n",
            "Epoch 312/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 283ms/step - accuracy: 0.7058 - loss: 0.6719 - val_accuracy: 0.6497 - val_loss: 0.8181 - learning_rate: 7.5000e-05\n",
            "Epoch 313/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 269ms/step - accuracy: 0.7061 - loss: 0.6742 - val_accuracy: 0.6397 - val_loss: 0.8227 - learning_rate: 7.5000e-05\n",
            "Epoch 314/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.7051 - loss: 0.6742 - val_accuracy: 0.6402 - val_loss: 0.8210 - learning_rate: 7.5000e-05\n",
            "Epoch 315/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 280ms/step - accuracy: 0.7232 - loss: 0.6523 - val_accuracy: 0.6481 - val_loss: 0.8197 - learning_rate: 7.5000e-05\n",
            "Epoch 316/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.7079 - loss: 0.6620 - val_accuracy: 0.6406 - val_loss: 0.8214 - learning_rate: 7.5000e-05\n",
            "Epoch 317/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 272ms/step - accuracy: 0.7044 - loss: 0.6728 - val_accuracy: 0.6424 - val_loss: 0.8229 - learning_rate: 7.5000e-05\n",
            "Epoch 318/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.7056 - loss: 0.6653 - val_accuracy: 0.6455 - val_loss: 0.8231 - learning_rate: 7.5000e-05\n",
            "Epoch 319/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 283ms/step - accuracy: 0.7139 - loss: 0.6507 - val_accuracy: 0.6439 - val_loss: 0.8203 - learning_rate: 7.5000e-05\n",
            "Epoch 320/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 274ms/step - accuracy: 0.7095 - loss: 0.6683 - val_accuracy: 0.6393 - val_loss: 0.8245 - learning_rate: 7.5000e-05\n",
            "Epoch 321/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.7156 - loss: 0.6526 - val_accuracy: 0.6446 - val_loss: 0.8164 - learning_rate: 3.7500e-05\n",
            "Epoch 322/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.7175 - loss: 0.6542 - val_accuracy: 0.6415 - val_loss: 0.8222 - learning_rate: 3.7500e-05\n",
            "Epoch 323/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 279ms/step - accuracy: 0.7109 - loss: 0.6549 - val_accuracy: 0.6488 - val_loss: 0.8210 - learning_rate: 3.7500e-05\n",
            "Epoch 324/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.7142 - loss: 0.6562 - val_accuracy: 0.6459 - val_loss: 0.8197 - learning_rate: 3.7500e-05\n",
            "Epoch 325/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.7120 - loss: 0.6625 - val_accuracy: 0.6457 - val_loss: 0.8226 - learning_rate: 3.7500e-05\n",
            "Epoch 326/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 283ms/step - accuracy: 0.7084 - loss: 0.6565 - val_accuracy: 0.6466 - val_loss: 0.8170 - learning_rate: 3.7500e-05\n",
            "Epoch 327/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.7148 - loss: 0.6433 - val_accuracy: 0.6466 - val_loss: 0.8186 - learning_rate: 3.7500e-05\n",
            "Epoch 328/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 269ms/step - accuracy: 0.7182 - loss: 0.6470 - val_accuracy: 0.6503 - val_loss: 0.8162 - learning_rate: 3.7500e-05\n",
            "Epoch 329/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.7167 - loss: 0.6527 - val_accuracy: 0.6477 - val_loss: 0.8149 - learning_rate: 3.7500e-05\n",
            "Epoch 330/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 280ms/step - accuracy: 0.7185 - loss: 0.6500 - val_accuracy: 0.6501 - val_loss: 0.8161 - learning_rate: 3.7500e-05\n",
            "Epoch 331/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.7159 - loss: 0.6537 - val_accuracy: 0.6444 - val_loss: 0.8188 - learning_rate: 3.7500e-05\n",
            "Epoch 332/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.7161 - loss: 0.6568 - val_accuracy: 0.6481 - val_loss: 0.8203 - learning_rate: 3.7500e-05\n",
            "Epoch 333/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.7174 - loss: 0.6518 - val_accuracy: 0.6468 - val_loss: 0.8208 - learning_rate: 3.7500e-05\n",
            "Epoch 334/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.7126 - loss: 0.6507 - val_accuracy: 0.6477 - val_loss: 0.8213 - learning_rate: 3.7500e-05\n",
            "Epoch 335/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.7220 - loss: 0.6446 - val_accuracy: 0.6466 - val_loss: 0.8196 - learning_rate: 3.7500e-05\n",
            "Epoch 336/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.7222 - loss: 0.6405 - val_accuracy: 0.6488 - val_loss: 0.8202 - learning_rate: 3.7500e-05\n",
            "Epoch 337/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 279ms/step - accuracy: 0.7174 - loss: 0.6381 - val_accuracy: 0.6563 - val_loss: 0.8215 - learning_rate: 3.7500e-05\n",
            "Epoch 338/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 275ms/step - accuracy: 0.7138 - loss: 0.6525 - val_accuracy: 0.6537 - val_loss: 0.8199 - learning_rate: 3.7500e-05\n",
            "Epoch 339/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 271ms/step - accuracy: 0.7235 - loss: 0.6397 - val_accuracy: 0.6548 - val_loss: 0.8178 - learning_rate: 3.7500e-05\n",
            "Epoch 340/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.7285 - loss: 0.6306 - val_accuracy: 0.6574 - val_loss: 0.8213 - learning_rate: 3.7500e-05\n",
            "Epoch 341/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.7138 - loss: 0.6519 - val_accuracy: 0.6546 - val_loss: 0.8202 - learning_rate: 3.7500e-05\n",
            "Epoch 342/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 265ms/step - accuracy: 0.7251 - loss: 0.6380 - val_accuracy: 0.6546 - val_loss: 0.8180 - learning_rate: 1.8750e-05\n",
            "Epoch 343/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 271ms/step - accuracy: 0.7279 - loss: 0.6346 - val_accuracy: 0.6559 - val_loss: 0.8157 - learning_rate: 1.8750e-05\n",
            "Epoch 344/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.7319 - loss: 0.6284 - val_accuracy: 0.6570 - val_loss: 0.8163 - learning_rate: 1.8750e-05\n",
            "Epoch 345/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 270ms/step - accuracy: 0.7266 - loss: 0.6355 - val_accuracy: 0.6543 - val_loss: 0.8179 - learning_rate: 1.8750e-05\n",
            "Epoch 346/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.7204 - loss: 0.6425 - val_accuracy: 0.6534 - val_loss: 0.8129 - learning_rate: 1.8750e-05\n",
            "Epoch 347/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.7215 - loss: 0.6340 - val_accuracy: 0.6572 - val_loss: 0.8137 - learning_rate: 1.8750e-05\n",
            "Epoch 348/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.7277 - loss: 0.6301 - val_accuracy: 0.6592 - val_loss: 0.8163 - learning_rate: 1.8750e-05\n",
            "Epoch 349/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 274ms/step - accuracy: 0.7284 - loss: 0.6367 - val_accuracy: 0.6603 - val_loss: 0.8148 - learning_rate: 1.8750e-05\n",
            "Epoch 350/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.7371 - loss: 0.6252 - val_accuracy: 0.6572 - val_loss: 0.8133 - learning_rate: 1.8750e-05\n",
            "Epoch 351/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 269ms/step - accuracy: 0.7300 - loss: 0.6387 - val_accuracy: 0.6539 - val_loss: 0.8166 - learning_rate: 1.8750e-05\n",
            "Epoch 352/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.7214 - loss: 0.6382 - val_accuracy: 0.6568 - val_loss: 0.8157 - learning_rate: 1.8750e-05\n",
            "Epoch 353/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 275ms/step - accuracy: 0.7242 - loss: 0.6348 - val_accuracy: 0.6574 - val_loss: 0.8129 - learning_rate: 1.8750e-05\n",
            "Epoch 354/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.7221 - loss: 0.6325 - val_accuracy: 0.6559 - val_loss: 0.8149 - learning_rate: 1.8750e-05\n",
            "Epoch 355/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 281ms/step - accuracy: 0.7224 - loss: 0.6387 - val_accuracy: 0.6574 - val_loss: 0.8174 - learning_rate: 1.8750e-05\n",
            "Epoch 356/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 270ms/step - accuracy: 0.7231 - loss: 0.6342 - val_accuracy: 0.6568 - val_loss: 0.8145 - learning_rate: 1.8750e-05\n",
            "Epoch 357/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.7196 - loss: 0.6349 - val_accuracy: 0.6577 - val_loss: 0.8158 - learning_rate: 1.8750e-05\n",
            "Epoch 358/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 274ms/step - accuracy: 0.7192 - loss: 0.6399 - val_accuracy: 0.6590 - val_loss: 0.8149 - learning_rate: 1.8750e-05\n",
            "Epoch 359/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 287ms/step - accuracy: 0.7318 - loss: 0.6235 - val_accuracy: 0.6550 - val_loss: 0.8158 - learning_rate: 9.3750e-06\n",
            "Epoch 360/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 264ms/step - accuracy: 0.7331 - loss: 0.6232 - val_accuracy: 0.6548 - val_loss: 0.8170 - learning_rate: 9.3750e-06\n",
            "Epoch 361/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 271ms/step - accuracy: 0.7265 - loss: 0.6268 - val_accuracy: 0.6561 - val_loss: 0.8155 - learning_rate: 9.3750e-06\n",
            "Epoch 362/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.7322 - loss: 0.6263 - val_accuracy: 0.6563 - val_loss: 0.8148 - learning_rate: 9.3750e-06\n",
            "Epoch 363/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.7264 - loss: 0.6351 - val_accuracy: 0.6574 - val_loss: 0.8150 - learning_rate: 9.3750e-06\n",
            "Epoch 364/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 286ms/step - accuracy: 0.7320 - loss: 0.6237 - val_accuracy: 0.6608 - val_loss: 0.8145 - learning_rate: 9.3750e-06\n",
            "Epoch 365/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 272ms/step - accuracy: 0.7314 - loss: 0.6233 - val_accuracy: 0.6568 - val_loss: 0.8145 - learning_rate: 9.3750e-06\n",
            "Epoch 366/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 282ms/step - accuracy: 0.7340 - loss: 0.6254 - val_accuracy: 0.6572 - val_loss: 0.8150 - learning_rate: 9.3750e-06\n",
            "Epoch 367/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 272ms/step - accuracy: 0.7278 - loss: 0.6374 - val_accuracy: 0.6557 - val_loss: 0.8145 - learning_rate: 9.3750e-06\n",
            "Epoch 368/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.7243 - loss: 0.6286 - val_accuracy: 0.6561 - val_loss: 0.8165 - learning_rate: 9.3750e-06\n",
            "Epoch 369/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.7234 - loss: 0.6299 - val_accuracy: 0.6579 - val_loss: 0.8143 - learning_rate: 9.3750e-06\n",
            "Epoch 370/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 289ms/step - accuracy: 0.7256 - loss: 0.6251 - val_accuracy: 0.6572 - val_loss: 0.8147 - learning_rate: 9.3750e-06\n",
            "Epoch 371/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.7297 - loss: 0.6300 - val_accuracy: 0.6552 - val_loss: 0.8138 - learning_rate: 4.6875e-06\n",
            "Epoch 372/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 273ms/step - accuracy: 0.7357 - loss: 0.6225 - val_accuracy: 0.6572 - val_loss: 0.8152 - learning_rate: 4.6875e-06\n",
            "Epoch 373/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.7308 - loss: 0.6222 - val_accuracy: 0.6565 - val_loss: 0.8149 - learning_rate: 4.6875e-06\n",
            "Epoch 374/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 284ms/step - accuracy: 0.7353 - loss: 0.6165 - val_accuracy: 0.6559 - val_loss: 0.8151 - learning_rate: 4.6875e-06\n",
            "Epoch 375/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 277ms/step - accuracy: 0.7189 - loss: 0.6375 - val_accuracy: 0.6557 - val_loss: 0.8146 - learning_rate: 4.6875e-06\n",
            "Epoch 376/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.7208 - loss: 0.6283 - val_accuracy: 0.6592 - val_loss: 0.8144 - learning_rate: 4.6875e-06\n",
            "Epoch 377/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 288ms/step - accuracy: 0.7304 - loss: 0.6254 - val_accuracy: 0.6561 - val_loss: 0.8152 - learning_rate: 4.6875e-06\n",
            "Epoch 378/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 268ms/step - accuracy: 0.7329 - loss: 0.6167 - val_accuracy: 0.6585 - val_loss: 0.8155 - learning_rate: 4.6875e-06\n",
            "Epoch 379/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.7283 - loss: 0.6201 - val_accuracy: 0.6581 - val_loss: 0.8154 - learning_rate: 4.6875e-06\n",
            "Epoch 380/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.7248 - loss: 0.6268 - val_accuracy: 0.6590 - val_loss: 0.8145 - learning_rate: 4.6875e-06\n",
            "Epoch 381/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 287ms/step - accuracy: 0.7282 - loss: 0.6236 - val_accuracy: 0.6568 - val_loss: 0.8154 - learning_rate: 4.6875e-06\n",
            "Epoch 382/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 273ms/step - accuracy: 0.7360 - loss: 0.6220 - val_accuracy: 0.6579 - val_loss: 0.8151 - learning_rate: 4.6875e-06\n",
            "Epoch 383/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 276ms/step - accuracy: 0.7278 - loss: 0.6255 - val_accuracy: 0.6581 - val_loss: 0.8151 - learning_rate: 2.3438e-06\n",
            "Epoch 384/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 278ms/step - accuracy: 0.7325 - loss: 0.6226 - val_accuracy: 0.6579 - val_loss: 0.8151 - learning_rate: 2.3438e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fbd8204a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# â”€â”€â”€ Evaluation â”€â”€â”€\n",
        "y_probs = model.predict([X_seq_val, X_meta_val])\n",
        "y_pred = np.argmax(y_probs, axis=1)\n",
        "\n",
        "labels = sorted(np.unique(y_val_multi))\n",
        "class_names = label_encoder.inverse_transform(labels)\n",
        "\n",
        "print(\"\\nğŸ“Š Classification Report (Raw):\")\n",
        "print(classification_report(y_val_multi, y_pred, labels=labels, target_names=class_names))\n",
        "\n",
        "# â”€â”€â”€ Threshold tuning for a target class â”€â”€â”€\n",
        "target_class = 'tp1'  # change this to any class name from class_names\n",
        "if target_class in class_names:\n",
        "    class_idx = label_encoder.transform([target_class])[0]\n",
        "    precision, recall, thresholds = precision_recall_curve(\n",
        "        (y_val_multi == class_idx), y_probs[:, class_idx]\n",
        "    )\n",
        "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "    best_thresh = thresholds[np.argmax(f1_scores)]\n",
        "    print(f\"\\nğŸ“Š Auto-tuned {target_class} Threshold = {best_thresh:.2f}\")\n",
        "    joblib.dump(best_thresh, f\"{target_class}_Threshold.pkl\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ Target class '{target_class}' not found in current model outputs. Available classes: {class_names}\")\n",
        "\n",
        "# â”€â”€â”€ Confusion Matrix & ROC AUC â”€â”€â”€\n",
        "print(\"\\nğŸ“Š Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val_multi, y_pred))\n",
        "\n",
        "try:\n",
        "    auc_score = roc_auc_score(y_val_multi, y_probs, multi_class='ovr')\n",
        "    print(f\"ğŸ§ª ROC AUC Score: {auc_score:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"âš ï¸ ROC AUC calculation skipped: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxJ7f3f6ng7B",
        "outputId": "c2656347-bba9-4c73-f94b-2aefb30f1933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step\n",
            "\n",
            "ğŸ“Š Classification Report (Raw):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       0.62      0.64      0.63      1504\n",
            "        skip       0.63      0.55      0.59      1504\n",
            "         tp1       0.73      0.79      0.76      1505\n",
            "\n",
            "    accuracy                           0.66      4513\n",
            "   macro avg       0.66      0.66      0.66      4513\n",
            "weighted avg       0.66      0.66      0.66      4513\n",
            "\n",
            "\n",
            "ğŸ“Š Auto-tuned tp1 Threshold = 0.44\n",
            "\n",
            "ğŸ“Š Confusion Matrix:\n",
            "[[ 963  337  204]\n",
            " [ 437  829  238]\n",
            " [ 164  151 1190]]\n",
            "ğŸ§ª ROC AUC Score: 0.8312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Binary TP2 Model (Unchanged) â”€â”€â”€\n",
        "seq_in = layers.Input(shape=(SEQLEN, 5))\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(seq_in)\n",
        "x = layers.LayerNormalization()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "x = layers.LayerNormalization()(x)\n",
        "meta_in = layers.Input(shape=(X_meta.shape[1],))\n",
        "x = layers.concatenate([x, meta_in])\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "binary_model = models.Model([seq_in, meta_in], out, name=\"TP2-LSTM-Binary\")\n",
        "binary_model.compile(optimizer=tf.keras.optimizers.Adam(0.0003),\n",
        "                    loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "binary_model.fit([X_seq_train, X_meta_train], y_train_bin,\n",
        "                validation_data=([X_seq_val, X_meta_val], y_val_bin),\n",
        "                epochs=500, batch_size=128, callbacks=[es, rlr], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDj4_YgPrP5Q",
        "outputId": "829857e1-69ab-4720-ed21-c90608cfc986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 488ms/step - accuracy: 0.9883 - loss: 0.0399 - val_accuracy: 1.0000 - val_loss: 6.5558e-05 - learning_rate: 3.0000e-04\n",
            "Epoch 2/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 1.2856e-04 - val_accuracy: 1.0000 - val_loss: 1.7806e-05 - learning_rate: 3.0000e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 4.8712e-05 - val_accuracy: 1.0000 - val_loss: 6.9375e-06 - learning_rate: 3.0000e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 2.3381e-05 - val_accuracy: 1.0000 - val_loss: 3.4135e-06 - learning_rate: 3.0000e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 1.4109e-05 - val_accuracy: 1.0000 - val_loss: 1.9971e-06 - learning_rate: 3.0000e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 9.5784e-06 - val_accuracy: 1.0000 - val_loss: 1.2754e-06 - learning_rate: 3.0000e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 6.5704e-06 - val_accuracy: 1.0000 - val_loss: 8.7790e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 5.7499e-06 - val_accuracy: 1.0000 - val_loss: 6.1639e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 4.3134e-06 - val_accuracy: 1.0000 - val_loss: 4.5892e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 3.8116e-06 - val_accuracy: 1.0000 - val_loss: 3.4572e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 3.4789e-06 - val_accuracy: 1.0000 - val_loss: 2.6962e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 2.4047e-06 - val_accuracy: 1.0000 - val_loss: 2.1412e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 2.2180e-06 - val_accuracy: 1.0000 - val_loss: 1.7189e-07 - learning_rate: 3.0000e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 2.0951e-06 - val_accuracy: 1.0000 - val_loss: 1.5437e-07 - learning_rate: 1.5000e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 2.0936e-06 - val_accuracy: 1.0000 - val_loss: 1.3828e-07 - learning_rate: 1.5000e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 1.7454e-06 - val_accuracy: 1.0000 - val_loss: 1.2366e-07 - learning_rate: 1.5000e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 1.6463e-06 - val_accuracy: 1.0000 - val_loss: 1.1069e-07 - learning_rate: 1.5000e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 1.3973e-06 - val_accuracy: 1.0000 - val_loss: 9.9520e-08 - learning_rate: 1.5000e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.4546e-06 - val_accuracy: 1.0000 - val_loss: 8.8849e-08 - learning_rate: 1.5000e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.5104e-06 - val_accuracy: 1.0000 - val_loss: 7.8939e-08 - learning_rate: 1.5000e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 1.1468e-06 - val_accuracy: 1.0000 - val_loss: 7.0982e-08 - learning_rate: 1.5000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79fbc0688490>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Binary Evaluation â”€â”€â”€\n",
        "pred_scores = binary_model.predict([X_seq_val, X_meta_val]).flatten()\n",
        "precision, recall, thresholds = precision_recall_curve(y_val_bin, pred_scores)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
        "best_binary_thresh = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"\\nğŸ“Š TP2 Binary Threshold (F1-Optimized): {best_binary_thresh:.2f}\")\n",
        "joblib.dump(best_binary_thresh, \"TP2_Binary_Threshold.pkl\")\n",
        "\n",
        "bin_preds = (pred_scores > best_binary_thresh).astype(int)\n",
        "print(\"\\nğŸ“Š TP2 Binary Classification Report:\")\n",
        "print(classification_report(y_val_bin, bin_preds))\n",
        "print(f\"ğŸ§ª ROC AUC Score: {roc_auc_score(y_val_bin, pred_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVcC3bQGrSgr",
        "outputId": "0f8fad13-5b4e-46cc-ba3e-a655f26df399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step\n",
            "\n",
            "ğŸ“Š TP2 Binary Threshold (F1-Optimized): 0.00\n",
            "\n",
            "ğŸ“Š TP2 Binary Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.00      0.00      4513\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.00      4513\n",
            "   macro avg       0.50      0.00      0.00      4513\n",
            "weighted avg       1.00      0.00      0.00      4513\n",
            "\n",
            "ğŸ§ª ROC AUC Score: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ Save Everything â”€â”€â”€\n",
        "model.save(\"AI_Trade_LSTM.h5\")\n",
        "binary_model.save(\"TP2_LSTM_Binary.h5\")\n",
        "\n",
        "# Export to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "tflite_model = converter.convert()\n",
        "with open(\"AI_Trade_LSTM.tflite\", \"wb\") as f: f.write(tflite_model)\n",
        "\n",
        "# Zip artifacts\n",
        "with zipfile.ZipFile(\"AI_Trade_Model.zip\", \"w\") as zipf:\n",
        "    for file in [\n",
        "        \"AI_Trade_LSTM.h5\", \"TP2_LSTM_Binary.h5\", \"AI_Trade_LSTM.tflite\",\n",
        "        \"Label_Encoder.pkl\", \"Scaler.pkl\",\n",
        "        \"TP2_Threshold.pkl\", \"TP2_Binary_Threshold.pkl\"\n",
        "    ]:\n",
        "        if os.path.exists(file):\n",
        "            zipf.write(file)\n",
        "\n",
        "print(\"\\nâœ… All model artifacts saved in: AI_Trade_Model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RerYQLGMrbDv",
        "outputId": "5f5f1cef-f4ee-4579-c6cb-13b85b3fa582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmphilaoku1'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): List[TensorSpec(shape=(None, 20, 5), dtype=tf.float32, name='sequence_input'), TensorSpec(shape=(None, 14), dtype=tf.float32, name='meta_input')]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134122843182032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843179344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843179920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843178960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843178576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843178768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843179536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843182224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843184144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843177424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843182608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843183568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843184720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843184528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843183184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843185296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843186064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843186640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843181072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843181456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843186256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843187024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843186832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843187600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843185872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843187792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843188368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843189328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843189136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843188560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843189520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134122843183760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\n",
            "âœ… All model artifacts saved in: AI_Trade_Model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"AI_Trade_Model.zip\")"
      ],
      "metadata": {
        "id": "0yBCDkv4reAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}